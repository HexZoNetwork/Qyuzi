# ğŸï¸ Qyuzi â€” Ferrari Lol

<div align="center">

```
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘
 â–ˆâ–ˆâ•‘â–„â–„ â–ˆâ–ˆâ•‘  â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘
 â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
  â•šâ•â•â–€â–€â•â•    â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•
```

**A Scalable Small Language Model with Advanced Cognitive Architecture**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Status](https://img.shields.io/badge/Status-Active_Development-yellow.svg)](https://github.com)

</div>

---

## ğŸš€ Overview

**Qyuzi** is a cutting-edge small language model (SSLM) designed to push the boundaries of efficient AGI. Built from scratch with PyTorch, Qyuzi implements state-of-the-art transformer architecture enhanced with advanced cognitive modules including:

- ğŸ§  **Conscious Working Memory** â€” 9-slot attention-based memory system
- âš¡ **Mixture of Experts (MoE)** â€” Dynamic expert routing for efficient scaling
- ğŸ”„ **Rotary Position Embedding (RoPE)** â€” Extended context window support (up to 32K tokens)
- ğŸ¯ **Causal Reasoning Engine** â€” Explicit causal inference mechanisms
- ğŸŒŒ **Multi-Stage Architecture** â€” Scalable from 670M to 8B parameters

Unlike typical language models, Qyuzi integrates neuromorphic computing concepts, vector-symbolic architectures, and dream-based memory consolidation to achieve human-like reasoning with minimal parameters.

---

## ğŸ“Š Model Stages

Qyuzi features a progressive scaling architecture:

| Stage           | Parameters | Layers | Hidden | FFN   | Experts  | Context | Status        |
| --------------- | ---------- | ------ | ------ | ----- | -------- | ------- | ------------- |
| **F** (Ferrari) | 670M       | 30     | 1024   | 4096  | Dense    | 16K     | âœ… Active      |
| **FH**          | 1.5B       | 36     | 1280   | 5120  | 8Ã—2 MoE  | 16K     | ğŸš§ Development |
| **SEC**         | 3.8B       | 42     | 1536   | 7680  | 16Ã—2 MoE | 32K     | ğŸ“‹ Planned     |
| **FIH**         | 8B         | 48     | 2048   | 10240 | 32Ã—2 MoE | 32K     | ğŸ“‹ Planned     |

*Active parameters in MoE variants are ~40% of total due to sparse expert activation*

---

## âœ¨ Key Features

### ğŸ—ï¸ Core Architecture
- **Transformer-based** with custom optimizations
- **Flash Attention** support for memory efficiency
- **Gradient checkpointing** for large-scale training
- **Mixed precision** (FP16/BF16) training
- **Rotary embeddings** for extended context

### ğŸ§¬ Advanced Modules
- **Conscious Working Memory** â€” Explicit storage slots for multi-step reasoning
- **Causal Engine** â€” Predicts causal relationships (cause/effect/spurious)
- **MoE Layers** â€” Up to 32 experts with top-k routing
- **Load Balancing** â€” Automatic expert utilization optimization
- **Auxiliary Loss** â€” Prevents expert collapse

### ğŸ”¬ Experimental Features
- **Spiking Neural Networks (SNN)** â€” Energy-efficient neuromorphic computing
- **Vector-Symbolic Architecture (VSA)** â€” Hyperdimensional reasoning
- **Dream Engine** â€” Nightly memory consolidation and replay
- **Self-Modeling** â€” Meta-cognitive awareness of own predictions
- **Quantum Swarm** â€” Distributed inference across multiple nodes

### ğŸ› ï¸ Training & Inference
- **Continuous learning** from web-scale data
- **Dynamic thinking** â€” Adjustable reasoning steps (1-16+)
- **Temperature-based sampling** â€” Controllable creativity
- **Checkpoint management** â€” Auto-save with versioning
- **Multi-modal** (planned) â€” Vision and audio understanding

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- CUDA 11.7+ (for GPU acceleration)
- 16GB+ RAM (32GB+ recommended for large stages)

### Setup

```bash
git clone https://github.com/HexZoNetwork/Qyuzi.git
cd Qyuzi

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install tiktoken requests datasets flash-attn --no-build-isolation
 #optional
pip install snnTorch hyperdimensional
```

### Quick Start

```bash
python main.py --mode train --stage f

python main.py --mode generate --prompt "What is consciousness?" --tokens 200 --steps 8

python main.py --mode eval --stage f

python main.py --mode swarm --nodes 1000 --topology hierarchical
```

---

## ğŸ® Usage

### Training

```bash
python main.py --mode train --stage f

python main.py --mode train --stage fh --snn --vsa --dream --selfmodel

python main.py --mode train --stage sec --multimodal
```

### Generation

```bash
python main.py --mode generate --prompt "Explain quantum mechanics" --tokens 500

python main.py --mode generate \
  --prompt "Solve the Riemann hypothesis" \
  --tokens 2000 \
  --steps 16 \
  --temp 0.7 \
  --stage fh

python main.py --mode generate \
  --prompt "Write a sci-fi story about AI" \
  --tokens 1000 \
  --temp 1.2 \
  --steps 4
```

### Swarm Deployment

```bash
python main.py --mode swarm --nodes 1000 --topology hierarchical

python main.py --mode swarm --nodes 500 --topology mesh

python main.py --mode swarm --nodes 2000 --topology ring
```

---

## ğŸ§© Architecture Deep Dive

### Conscious Working Memory

Qyuzi implements a 9-slot attention-based working memory inspired by cognitive science research:

```python
slots = [slot_1, slot_2, ..., slot_9]
gate_scores = softmax(linear(hidden_state))
working_memory = sum(gate_scores * slots)
```

### Mixture of Experts (MoE)

Dynamic expert routing reduces computation while scaling parameters:

```
Top-K Router â†’ Expert Selection â†’ Parallel Processing â†’ Weighted Combination
           â†“                                                  â†‘
    Load Balancing Loss â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Capacity Factor**: 1.25Ã— for overflow handling
- **Expert Dropout**: Prevents over-specialization
- **Auxiliary Loss**: Ensures balanced expert usage

### Causal Reasoning Engine

Predicts causal relationships between events:

```
Event A + Event B â†’ Neural Network â†’ [CAUSE, EFFECT, SPURIOUS]
```

Enables counterfactual reasoning and intervention planning.

---

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation âœ…
- [x] Core transformer architecture
- [x] 670M dense model (Ferrari)
- [x] RoPE positional encoding
- [x] Basic training pipeline

### Phase 2: Scaling ğŸš§
- [x] MoE implementation
- [ ] 1.5B MoE model (8 experts)
- [ ] 3.8B MoE model (16 experts)
- [ ] Context scaling to 32K tokens

### Phase 3: Advanced Cognition ğŸ“‹
- [ ] Spiking Neural Network co-processor
- [ ] Vector-Symbolic Architecture integration
- [ ] Dream-based memory consolidation
- [ ] Self-modeling module

### Phase 4: Multi-Modal ğŸ“‹
- [ ] Vision encoder (256Ã—256 â†’ 1024Ã—1024)
- [ ] Video understanding
- [ ] Audio input/output (Whisper + VALL-E)
- [ ] Multi-modal reasoning

### Phase 5: Autonomy ğŸŒŸ
- [ ] Recursive self-improvement
- [ ] Neuro-symbolic theorem proving (Lean 4)
- [ ] Robotic embodiment (ROS2)
- [ ] Chemical computing substrate

---

## ğŸ”§ Configuration

Set model stage and features via environment variables:

```bash
export QYUZI_STAGE=fh           # f, fh, sec, fih
export QYUZI_SNN=1              # Enable spiking neurons
export QYUZI_VSA=1              # Enable vector-symbolic arch
export QYUZI_DREAM=1            # Enable dream engine
export QYUZI_SELFMODEL=1        # Enable self-modeling
```

Or use CLI flags:

```bash
python main.py --stage fh --snn --vsa --dream --selfmodel
```

---

## ğŸ“ˆ Performance

*Benchmarks:*

| Stage          | Training Speed | Inference (bs=1) | Memory Usage |
| -------------- | -------------- | ---------------- | ------------ |
| F (670M)       | ~2.3K tok/s    | ~45 tok/s        | 9.5 GB       |
| FH (1.5B MoE)  | ~1.8K tok/s    | ~35 tok/s        | 14.2 GB      |
| SEC (3.8B MoE) | ~950 tok/s     | ~22 tok/s        | 20.8 GB      |

*Prediction I Dont Have Gpu Lol*

---

## ğŸ¤ Contributing

Qyuzi is an active research project. Contributions are welcome!

### Areas of Interest
- ğŸ§  Novel reasoning mechanisms
- âš¡ Training optimizations
- ğŸŒ Multi-modal architectures
- ğŸ”¬ Neuromorphic computing
- ğŸ“Š Evaluation frameworks

### How to Contribute
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ Citation

If you use Qyuzi in your research, please cite:

```bibtex
@software{Qyuzi,
  title={Qyuzi: A Scalable Small Language Model with Advanced Cognitive Architecture},
  author={HexZo Skibidi Toilet Ahh},
  year={2024},
  url={https://github.com/HexZoNetwork/Qyuzi}
}
```

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Flash Attention**
- **Rotary Embeddings**
- **Mixture of Experts**
- **Tiktoken**
- **PyTorch Team**

---

## ğŸ“§ Contact

For questions, collaborations, or just to chat about AGI:
- **Telegram**: [@HexZo_Not_Devz](https://t.me/HexZo_Not_Devz)
---

<div align="center">

**Qyuzi never sleeps. ğŸï¸ğŸ’¨**

*Built with ğŸ§  and âš¡ by A Single Person [just a kid]*


</div>

